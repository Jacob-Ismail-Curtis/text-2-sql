{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "\n",
    "import sqlite3\n",
    "import json\n",
    "import csv\n",
    "from typing import List, Tuple, Dict, Union\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set Gemini API key from .env file\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "MODEL_NAME = \"gemini-pro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Pydantic Models\n",
    "\n",
    "class RelevantData(BaseModel):\n",
    "    relevant_tables: List[str] = Field(\n",
    "        ..., description=\"List of relevant table names\"\n",
    "    )\n",
    "    relevant_columns: List[str] = Field(\n",
    "        ..., description=\"List of relevant column names in 'table.column' format\"\n",
    "    )\n",
    "\n",
    "\n",
    "class SQLQuery(BaseModel):\n",
    "    sql_query: str = Field(..., description=\"Generated SQL query\")\n",
    "\n",
    "\n",
    "class RelevantQueries(BaseModel):\n",
    "    relevant_queries: List[Dict] = Field(\n",
    "        ..., description=\"List of relevant past queries\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Base Agent Class\n",
    "\n",
    "class BaseAgent:\n",
    "    def __init__(self, model: str = MODEL_NAME):\n",
    "        self.model = model\n",
    "        self.gemini = genai.GenerativeModel(self.model)\n",
    "\n",
    "    def call_llm(self, prompt: str, response_model: type[BaseModel]) -> BaseModel:\n",
    "        \"\"\"Call Gemini API and get structured output\"\"\"\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [\"You are an assistant for structured outputs.\"],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"model\",\n",
    "                \"parts\": [\n",
    "                    \"Understood. I will provide responses in the requested format.\"\n",
    "                ],\n",
    "            },\n",
    "            {\"role\": \"user\", \"parts\": [prompt]},\n",
    "        ]\n",
    "\n",
    "        response = self.gemini.generate_content(messages)\n",
    "\n",
    "        try:\n",
    "            # Clean the response text\n",
    "            cleaned_response_text = response.text.strip()\n",
    "            if cleaned_response_text.startswith(\"```json\"):\n",
    "                cleaned_response_text = cleaned_response_text[7:]\n",
    "            elif cleaned_response_text.startswith(\"```JSON\"):\n",
    "                cleaned_response_text = cleaned_response_text[7:]\n",
    "            elif cleaned_response_text.startswith(\"```\"):\n",
    "                cleaned_response_text = cleaned_response_text[3:]\n",
    "\n",
    "            if cleaned_response_text.endswith(\"```\"):\n",
    "                cleaned_response_text = cleaned_response_text[:-3]\n",
    "\n",
    "            if cleaned_response_text.startswith(\"JSON\"):\n",
    "                cleaned_response_text = cleaned_response_text[4:]\n",
    "            elif cleaned_response_text.startswith(\"json\"):\n",
    "                cleaned_response_text = cleaned_response_text[4:]\n",
    "\n",
    "            cleaned_response_text = cleaned_response_text.strip()\n",
    "\n",
    "            # Attempt to parse the cleaned response text as JSON\n",
    "            response_json = json.loads(cleaned_response_text)\n",
    "            return response_model(**response_json)\n",
    "        except (json.JSONDecodeError, ValidationError) as e:\n",
    "            print(f\"Error parsing or validating response: {e}\")\n",
    "            print(f\"Cleaned response text: {cleaned_response_text}\")\n",
    "            raise ValueError(\"Failed to parse and validate LLM response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: RAG Agent Class\n",
    "\n",
    "class RAGAgent(BaseAgent):\n",
    "    def __init__(self, db_file: str):\n",
    "        super().__init__()\n",
    "        self.db_file = db_file\n",
    "\n",
    "    def extract_relevant_data(\n",
    "        self, query: str, relevant_queries: List[Dict], memory_results: List[Tuple]\n",
    "    ) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"Extract relevant tables and columns using LLM, database schema, and memory results.\"\"\"\n",
    "        schema = self.get_full_schema()\n",
    "        prompt = (\n",
    "            \"You are a system that extracts schema information for SQL queries. **You MUST ONLY use the tables and columns provided in the schema below. Do NOT hallucinate or use any other tables or columns.**\\n\"\n",
    "            f\"Schema:\\n{schema}\\n\"\n",
    "            f\"Relevant Queries: {relevant_queries}\\n\"\n",
    "            f\"Previous Results: {memory_results}\\n\"\n",
    "            f\"User Query: {query}\\n\"\n",
    "            \"Based on the user query, and considering the provided schema ONLY, provide a JSON object with:\\n\"\n",
    "            \"- 'relevant_tables': a list of the table names that are relevant to the query.\\n\"\n",
    "            \"- 'relevant_columns': a list of the column names (in 'table.column' format) that are relevant to the query.\\n\"\n",
    "            \"If no tables or columns are relevant, return an empty list for both.\\n\"\n",
    "            \"Example:\\n\"\n",
    "            \"Schema:\\nTable: employees, Columns: employee_id (INTEGER), name (TEXT), department (TEXT), salary (REAL)\\nTable: departments, Columns: department_id (INTEGER), department_name (TEXT)\\n\"\n",
    "            \"User Query: What is the average salary in the 'Sales' department?\\n\"\n",
    "            \"Response:\\n\"\n",
    "            '{\"relevant_tables\": [\"employees\", \"departments\"], \"relevant_columns\": [\"employees.salary\", \"departments.department_name\"]}\\n'\n",
    "            \"If the user asks a question that requires creating a new table or modifying data, return an empty list for both 'relevant_tables' and 'relevant_columns'.\"\n",
    "        )\n",
    "        structured_output: RelevantData = self.call_llm(prompt, RelevantData)\n",
    "        return structured_output.relevant_tables, structured_output.relevant_columns\n",
    "\n",
    "    def get_full_schema(self) -> str:\n",
    "        \"\"\"Retrieve full schema from the database.\"\"\"\n",
    "        schema_details = []\n",
    "        with sqlite3.connect(self.db_file) as conn:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "            tables = [row[0] for row in cursor.fetchall()]\n",
    "            for table in tables:\n",
    "                cursor.execute(f\"PRAGMA table_info({table});\")\n",
    "                columns = [f\"{row[1]} ({row[2]})\" for row in cursor.fetchall()]\n",
    "                schema_details.append(f\"Table: {table}, Columns: {', '.join(columns)}\")\n",
    "        return \"\\n\".join(schema_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: SQL Agent Class\n",
    "\n",
    "class SQLAgent(BaseAgent):\n",
    "    def __init__(self, db_file: str):\n",
    "        super().__init__()\n",
    "        self.db_file = db_file\n",
    "        self.rag_agent = RAGAgent(db_file)\n",
    "        self.max_refinement_iterations = 3\n",
    "\n",
    "    def generate_sql(\n",
    "        self,\n",
    "        tables: List[str],\n",
    "        columns: List[str],\n",
    "        query: str,\n",
    "        relevant_queries: List[Dict],\n",
    "        memory_results: List[Tuple],\n",
    "    ) -> str:\n",
    "        \"\"\"Generate initial SQL query using extracted tables, columns, and history.\"\"\"\n",
    "        schema = self.rag_agent.get_full_schema()\n",
    "        prompt = (\n",
    "            \"You are a SQL generation assistant. **You MUST ONLY use the tables and columns provided in the schema below. Do NOT hallucinate or use any other tables or columns.**\\n\"\n",
    "            f\"Schema:\\n{schema}\\n\"\n",
    "            f\"Relevant Tables: {tables}\\n\"\n",
    "            f\"Relevant Columns: {columns}\\n\"\n",
    "            f\"Relevant Queries: {relevant_queries}\\n\"\n",
    "            f\"Previous Results: {memory_results}\\n\"\n",
    "            f\"User Query: {query}\\n\"\n",
    "            \"Based on the user query, relevant tables, relevant columns, and the provided schema ONLY, generate a single valid SQL query that answers the query.\\n\"\n",
    "            \"Provide a valid SQL query as a JSON object with the key 'sql_query' and the SQL query as the string value. Do not nest the SQL query within another object.\\n\"\n",
    "            \"Example: {\\\"sql_query\\\": \\\"SELECT * FROM table WHERE condition\\\"}\\n\"\n",
    "            \"If the user asks a question that requires creating a new table or modifying data, return 'NOT_APPLICABLE'.\\n\"\n",
    "            \"If the user asks a question that does not require any table, select from 'Table_does_not_exist'.\"\n",
    "        )\n",
    "        structured_output: SQLQuery = self.call_llm(prompt, SQLQuery)\n",
    "        return structured_output.sql_query\n",
    "\n",
    "    def refine_sql(\n",
    "        self,\n",
    "        previous_sql_query: str,\n",
    "        query_results: List[Tuple],\n",
    "        user_query: str,\n",
    "        relevant_queries: List[Dict],\n",
    "        memory_results: List[Tuple],\n",
    "    ) -> str:\n",
    "        \"\"\"Refine the SQL query based on the results of the previous query.\"\"\"\n",
    "        schema = self.rag_agent.get_full_schema()\n",
    "        prompt = (\n",
    "            \"You are a SQL refinement assistant. You improve SQL queries iteratively based on feedback.\\n\"\n",
    "            f\"Schema:\\n{schema}\\n\"\n",
    "            f\"Previous SQL Query: {previous_sql_query}\\n\"\n",
    "            f\"Query Results: {query_results}\\n\"\n",
    "            f\"Relevant Queries: {relevant_queries}\\n\"\n",
    "            f\"Memory Results: {memory_results}\\n\"\n",
    "            f\"Original User Query: {user_query}\\n\"\n",
    "            \"Analyze the previous SQL query and its results. If the results are not satisfactory or if they do not fully address the original user query, generate a refined SQL query.\\n\"\n",
    "            \"Consider the following when refining:\\n\"\n",
    "            \"- Add or modify WHERE clauses to filter the results further.\\n\"\n",
    "            \"- Adjust JOIN conditions if necessary.\\n\"\n",
    "            \"- Add or change aggregate functions (e.g., COUNT, SUM, AVG).\\n\"\n",
    "            \"- Modify the selected columns.\\n\"\n",
    "            \"- Correct any errors in the previous query.\\n\"\n",
    "            \"If the results are satisfactory, return 'SATISFACTORY'.\\n\"\n",
    "            \"If you cannot determine how to refine the query further, return 'NO_FURTHER_REFINEMENT'.\\n\"\n",
    "            \"Provide the refined SQL query as a JSON object with the key 'sql_query'.\\n\"\n",
    "            \"Example:\\n\"\n",
    "            \"Previous SQL Query: SELECT department, AVG(salary) FROM employees GROUP BY department\\n\"\n",
    "            \"Query Results: [('Sales', 55000.0), ('HR', 60000.0)]\\n\"\n",
    "            \"Original User Query: What is the average salary in each department for employees hired after 2021?\\n\"\n",
    "            \"Response:\\n\"\n",
    "            '{\"sql_query\": \"SELECT department, AVG(salary) FROM employees WHERE hire_date > \\'2021-12-31\\' GROUP BY department\"}\\n'\n",
    "            \"Previous SQL Query: SELECT name FROM employees WHERE is_manager = 'yes'\\n\"\n",
    "            \"Query Results: [('John Doe',), ('Jane Smith',)]\\n\"\n",
    "            \"Original User Query: Who are the managers in the Sales department?\\n\"\n",
    "            \"Response:\\n\"\n",
    "            '{\"sql_query\": \"SELECT name FROM employees WHERE is_manager = \\'yes\\' AND department = \\'Sales\\'\"}\\n'\n",
    "        )\n",
    "        structured_output: SQLQuery = self.call_llm(prompt, SQLQuery)\n",
    "        return structured_output.sql_query\n",
    "\n",
    "    def generate_and_refine_sql(\n",
    "        self,\n",
    "        tables: List[str],\n",
    "        columns: List[str],\n",
    "        query: str,\n",
    "        relevant_queries: List[Dict],\n",
    "        memory_results: List[Tuple],\n",
    "    ) -> str:\n",
    "        \"\"\"Generate and refine SQL queries iteratively until satisfactory or max iterations reached.\"\"\"\n",
    "        current_sql_query = self.generate_sql(\n",
    "            tables, columns, query, relevant_queries, memory_results\n",
    "        )\n",
    "        print(f\"    Initial SQL Query: {current_sql_query}\")\n",
    "\n",
    "        for iteration in range(self.max_refinement_iterations):\n",
    "            if current_sql_query in [\n",
    "                \"NOT_APPLICABLE\",\n",
    "                \"NO_FURTHER_REFINEMENT\",\n",
    "                \"SATISFACTORY\",\n",
    "            ]:\n",
    "                print(\n",
    "                    f\"    Final SQL Query (Iteration {iteration+1}): {current_sql_query}\"\n",
    "                )\n",
    "                return current_sql_query\n",
    "\n",
    "            with sqlite3.connect(self.db_file) as conn:\n",
    "                cursor = conn.cursor()\n",
    "                try:\n",
    "                    cursor.execute(current_sql_query)\n",
    "                    query_results = cursor.fetchall()\n",
    "                except sqlite3.Error as e:\n",
    "                    print(f\"    SQL Execution Error (Iteration {iteration + 1}): {e}\")\n",
    "                    query_results = []\n",
    "\n",
    "            print(f\"    Query Results (Iteration {iteration+1}): {query_results}\")\n",
    "\n",
    "            new_sql_query = self.refine_sql(\n",
    "                current_sql_query,\n",
    "                query_results,\n",
    "                query,\n",
    "                relevant_queries,\n",
    "                memory_results,\n",
    "            )\n",
    "\n",
    "            if new_sql_query == \"SATISFACTORY\":\n",
    "                print(f\"    SQL Refinement Satisfactory (Iteration {iteration+1})\")\n",
    "                return current_sql_query\n",
    "            elif new_sql_query == \"NO_FURTHER_REFINEMENT\":\n",
    "                print(\n",
    "                    f\"    SQL Refinement Could Not Be Improved Further (Iteration {iteration+1})\"\n",
    "                )\n",
    "                return current_sql_query\n",
    "            else:\n",
    "                current_sql_query = new_sql_query\n",
    "                print(f\"    Refined SQL Query (Iteration {iteration+1}): {current_sql_query}\")\n",
    "\n",
    "        print(\n",
    "            f\"    Max Refinement Iterations Reached ({self.max_refinement_iterations})\"\n",
    "        )\n",
    "        return current_sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Conversational Agent Class\n",
    "\n",
    "class ConversationalAgent(BaseAgent):\n",
    "    def __init__(self, memory_file: str):\n",
    "        super().__init__()\n",
    "        self.memory_file = memory_file\n",
    "\n",
    "    def get_chat_history(self, current_input: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant queries from memory for the current input.\n",
    "        Considers queries relevant if they provide context or information\n",
    "        that would be helpful in answering the current input.\n",
    "        \"\"\"\n",
    "        with open(self.memory_file, mode=\"r\", newline=\"\") as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            memory_buffer = [row for row in reader]\n",
    "\n",
    "        memory_json = json.dumps(memory_buffer)\n",
    "        prompt = (\n",
    "            \"You are an assistant that retrieves relevant past queries from a memory buffer to provide context for answering the current input. **You MUST ONLY use the queries provided in the memory buffer. Do NOT hallucinate or use any other queries.**\\n\"\n",
    "            f\"Memory Buffer (JSON):\\n{memory_json}\\n\"\n",
    "            f\"Current Input: {current_input}\\n\"\n",
    "            \"Analyze the current input and determine which past queries from the memory buffer are relevant. Consider the following when determining relevancy:\\n\"\n",
    "            \"- The past query provides definitions or context related to terms in the current input.\\n\"\n",
    "            \"- The past query asks a similar question to the current input, even if about a different entity.\\n\"\n",
    "            \"- The past query provides data that might be useful for comparison or contrast with the current input.\\n\"\n",
    "            \"- The past query was part of a sequence of questions leading up to the current input.\\n\"\n",
    "            \"A past query is considered relevant if it provides context or information that would be helpful in answering the current input.\\n\"\n",
    "            \"Return the relevant past queries as a JSON object under the key 'relevant_queries'.\\n\"\n",
    "            \"Example:\\n\"\n",
    "            \"Memory Buffer (JSON):\\n\"\n",
    "            '[{\"User Query\": \"What is the capital of France?\", \"Relevant Tables\": [], \"Relevant Columns\": [], \"Generated SQL Query\": \"NOT_APPLICABLE\", \"Execution Results\": \"[]\"}, {\"User Query\": \"How many departments are there?\", \"Relevant Tables\": [\"departments\"], \"Relevant Columns\": [\"departments.department_id\"], \"Generated SQL Query\": \"SELECT COUNT(department_id) FROM departments\", \"Execution Results\": \"[[5]]\"}]\\n'\n",
    "            \"Current Input: Which department has the most employees?\\n\"\n",
    "            \"Response:\\n\"\n",
    "            '{\"relevant_queries\": [{\"User Query\": \"How many departments are there?\", \"Relevant Tables\": [\"departments\"], \"Relevant Columns\": [\"departments.department_id\"], \"Generated SQL Query\": \"SELECT COUNT(department_id) FROM departments\", \"Execution Results\": \"[[5]]\"}]}\\n'\n",
    "            \"If no relevant queries are found, return an empty list.\\n\"\n",
    "        )\n",
    "        structured_output: RelevantQueries = self.call_llm(prompt, RelevantQueries)\n",
    "        return structured_output.relevant_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: RAG Pipeline Class\n",
    "\n",
    "class RAGPipeline:\n",
    "    def __init__(self, db_file: str, user_query: str):\n",
    "        self.db_file = db_file\n",
    "        self.user_query = user_query\n",
    "        self.memory_file = \"memory_buffer.csv\"\n",
    "        self.conversational_agent = ConversationalAgent(self.memory_file)\n",
    "        self.rag_agent = RAGAgent(db_file)\n",
    "        self.sql_agent = SQLAgent(db_file)\n",
    "        self.initialize_memory()\n",
    "\n",
    "    def initialize_memory(self):\n",
    "        \"\"\"Initialize the memory buffer CSV.\"\"\"\n",
    "        if not os.path.exists(self.memory_file):\n",
    "            with open(self.memory_file, mode=\"w\", newline=\"\") as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(\n",
    "                    [\n",
    "                        \"User Query\",\n",
    "                        \"Relevant Tables\",\n",
    "                        \"Relevant Columns\",\n",
    "                        \"Generated SQL Query\",\n",
    "                        \"Execution Results\",\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "    def update_memory(\n",
    "        self,\n",
    "        user_query: str,\n",
    "        tables: List[str],\n",
    "        columns: List[str],\n",
    "        sql_query: str,\n",
    "        results: List[Tuple],\n",
    "    ):\n",
    "        \"\"\"Update the memory buffer with the latest context.\"\"\"\n",
    "        with open(self.memory_file, mode=\"a\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(\n",
    "                [\n",
    "                    user_query,\n",
    "                    json.dumps(tables),\n",
    "                    json.dumps(columns),\n",
    "                    sql_query,\n",
    "                    json.dumps(results),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def fetch_relevant_from_memory(\n",
    "        self, relevant_queries: List[Dict]\n",
    "    ) -> Tuple[List[str], List[str], List[Tuple]]:\n",
    "        \"\"\"Fetch relevant tables, columns, and results from memory based on retrieved queries.\"\"\"\n",
    "        relevant_tables = set()\n",
    "        relevant_columns = set()\n",
    "        relevant_results = []\n",
    "        with open(self.memory_file, mode=\"r\", newline=\"\") as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            for row in reader:\n",
    "                if any(\n",
    "                    rq[\"User Query\"] == row[\"User Query\"] for rq in relevant_queries\n",
    "                ):\n",
    "                    relevant_tables.update(json.loads(row[\"Relevant Tables\"]))\n",
    "                    relevant_columns.update(json.loads(row[\"Relevant Columns\"]))\n",
    "                    relevant_results.append(json.loads(row[\"Execution Results\"]))\n",
    "        return list(relevant_tables), list(relevant_columns), relevant_results\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            # Get relevant history for context\n",
    "            relevant_queries = self.conversational_agent.get_chat_history(\n",
    "                self.user_query\n",
    "            )\n",
    "\n",
    "            print(\"Processing Query:\")\n",
    "            print(f\"  Relevant Queries for Context: {relevant_queries}\")\n",
    "\n",
    "            # Fetch relevant tables, columns, and results from memory\n",
    "            memory_tables, memory_columns, memory_results = (\n",
    "                self.fetch_relevant_from_memory(relevant_queries)\n",
    "            )\n",
    "\n",
    "            # Step 1: Extract relevant tables and columns\n",
    "            rag_tables, rag_columns = self.rag_agent.extract_relevant_data(\n",
    "                self.user_query, relevant_queries, memory_results\n",
    "            )\n",
    "            relevant_tables = list(set(memory_tables + rag_tables))\n",
    "            relevant_columns = list(set(memory_columns + rag_columns))\n",
    "\n",
    "            print(f\"  Relevant Tables: {relevant_tables}\")\n",
    "            print(f\"  Relevant Columns: {relevant_columns}\")\n",
    "\n",
    "            # Step 2: Generate and Refine SQL query\n",
    "            final_sql_query = self.sql_agent.generate_and_refine_sql(\n",
    "                relevant_tables,\n",
    "                relevant_columns,\n",
    "                self.user_query,\n",
    "                relevant_queries,\n",
    "                memory_results,\n",
    "            )\n",
    "\n",
    "            print(f\"  Final SQL Query: {final_sql_query}\")\n",
    "\n",
    "            # Step 3: Execute SQL query\n",
    "            results = self.execute_sql_with_validation(final_sql_query)\n",
    "            print(f\"  Query Results: {results}\")\n",
    "\n",
    "            # Update memory buffer\n",
    "            self.update_memory(\n",
    "                self.user_query,\n",
    "                relevant_tables,\n",
    "                relevant_columns,\n",
    "                final_sql_query,\n",
    "                results,\n",
    "            )\n",
    "\n",
    "            # Step 4: Take new user input\n",
    "            self.user_query = input(\"Enter your next question: \").strip()\n",
    "\n",
    "    def execute_sql_with_validation(self, sql_query: str) -> List[Tuple]:\n",
    "        \"\"\"Execute SQL query with retries if errors occur.\"\"\"\n",
    "        attempt = 0\n",
    "        max_attempts = 3\n",
    "        while attempt < max_attempts:\n",
    "            try:\n",
    "                with sqlite3.connect(self.db_file) as conn:\n",
    "                    cursor = conn.cursor()\n",
    "                    cursor.execute(sql_query)\n",
    "                    return cursor.fetchall()\n",
    "            except sqlite3.Error as e:\n",
    "                print(f\"SQL Execution Error (Attempt {attempt + 1}): {e}\")\n",
    "                attempt += 1\n",
    "                sql_query = self.sql_agent.generate_sql(\n",
    "                    [], [], self.user_query, [], []\n",
    "                )  # Regenerate SQL on error\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Query:\n",
      "  Relevant Queries for Context: [{'User Query': 'How many people have booked at least 50 hours before 01/05/2024?', 'Relevant Tables': '[\"holiday_balance\"]', 'Relevant Columns': '[\"holiday_balance.booked\"]', 'Generated SQL Query': \"SELECT\\nCOUNT(DISTINCT colleague_id)\\nFROM holiday_balance\\nWHERE booked >= 50\\nAND report_date <= '2024-04-30'\", 'Execution Results': '[[0]]'}, {'User Query': 'How many people have booked at least 50 hours before 01/05/2024?', 'Relevant Tables': '[\"holiday_balance\"]', 'Relevant Columns': '[\"holiday_balance.booked\"]', 'Generated SQL Query': \"SELECT\\nCOUNT(DISTINCT colleague_id)\\nFROM holiday_balance\\nWHERE booked >= 50\\nAND report_date < '2024-05-01'\\nAND using_workday = 1\", 'Execution Results': '[[0]]'}]\n",
      "  Relevant Tables: ['holiday_balance']\n",
      "  Relevant Columns: ['holiday_balance.report_date', 'holiday_balance.booked']\n",
      "    Initial SQL Query: SELECT\n",
      "COUNT(DISTINCT colleague_id)\n",
      "FROM holiday_balance\n",
      "WHERE booked >= 50\n",
      "AND report_date < '2024-05-01'\n",
      "    Query Results (Iteration 1): [(0,)]\n",
      "    Refined SQL Query (Iteration 1): SELECT\n",
      "COUNT(DISTINCT colleague_id)\n",
      "FROM holiday_balance\n",
      "WHERE booked >= 50\n",
      "AND report_date < '2024-05-01'\n",
      "AND NOT (coalesce(using_workday, 0) = 0)\n",
      "    Query Results (Iteration 2): [(0,)]\n",
      "    Refined SQL Query (Iteration 2): SELECT\n",
      "COUNT(DISTINCT colleague_id)\n",
      "FROM holiday_balance\n",
      "WHERE booked >= 50\n",
      "AND report_date < '2024-05-01'\n",
      "AND NOT (coalesce(using_workday, 0) = 0)\n",
      "    Query Results (Iteration 3): [(0,)]\n",
      "    Refined SQL Query (Iteration 3): SELECT\n",
      "COUNT(DISTINCT colleague_id)\n",
      "FROM holiday_balance\n",
      "WHERE booked >= 50\n",
      "AND NOT (coalesce(using_workday, 0) = 0)\n",
      "AND report_date < '2024-05-01'\n",
      "    Max Refinement Iterations Reached (3)\n",
      "  Final SQL Query: SELECT\n",
      "COUNT(DISTINCT colleague_id)\n",
      "FROM holiday_balance\n",
      "WHERE booked >= 50\n",
      "AND NOT (coalesce(using_workday, 0) = 0)\n",
      "AND report_date < '2024-05-01'\n",
      "  Query Results: [(0,)]\n",
      "Processing Query:\n",
      "  Relevant Queries for Context: [{'User Query': 'how many of these are managers', 'Relevant Tables': '[\"people\"]', 'Relevant Columns': '[\"people.is_manager\"]', 'Generated SQL Query': \"SELECT COUNT(*) FROM people WHERE is_manager = 'yes'\", 'Execution Results': '[[0]]'}, {'User Query': 'how manny of these are managers', 'Relevant Tables': '[\"people\"]', 'Relevant Columns': '[\"people.is_manager\"]', 'Generated SQL Query': \"SELECT COUNT(*) FROM people WHERE is_manager = 'yes' AND direct_line_manager_id IS NOT NULL AND location_name = 'Manchester' AND data_source = 'Workday'\", 'Execution Results': '[[0]]'}]\n",
      "  Relevant Tables: ['people']\n",
      "  Relevant Columns: ['people.is_manager']\n",
      "    Initial SQL Query: SELECT COUNT(*) FROM people WHERE is_manager = 'yes'\n",
      "    Query Results (Iteration 1): [(0,)]\n",
      "    Refined SQL Query (Iteration 1): SELECT COUNT(*) FROM people WHERE is_manager = 'yes' AND location_name = 'Manchester' AND data_source = 'Workday'\n",
      "    Query Results (Iteration 2): [(0,)]\n",
      "    Refined SQL Query (Iteration 2): SELECT COUNT(*) FROM people WHERE is_manager = 'yes' AND location_name = 'Manchester' AND data_source = 'Workday' AND worker_type = 'Manager'\n",
      "    Query Results (Iteration 3): [(0,)]\n",
      "    Refined SQL Query (Iteration 3): SELECT COUNT(*) FROM people WHERE is_manager = 'yes' AND location_name = 'Manchester' AND data_source = 'Workday' AND worker_type = 'Manager' AND fte >= 1.0\n",
      "    Max Refinement Iterations Reached (3)\n",
      "  Final SQL Query: SELECT COUNT(*) FROM people WHERE is_manager = 'yes' AND location_name = 'Manchester' AND data_source = 'Workday' AND worker_type = 'Manager' AND fte >= 1.0\n",
      "  Query Results: [(0,)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m USER_QUERY \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow many people have booked at least 50 hours before 01/05/2024?\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Initial user query\u001b[39;00m\n\u001b[1;32m      6\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m RAGPipeline(DB_FILE, USER_QUERY)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[60], line 70\u001b[0m, in \u001b[0;36mRAGPipeline.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;66;03m# Get relevant history for context\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m         relevant_queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconversational_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_chat_history\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_query\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Query:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Relevant Queries for Context: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelevant_queries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[59], line 38\u001b[0m, in \u001b[0;36mConversationalAgent.get_chat_history\u001b[0;34m(self, current_input)\u001b[0m\n\u001b[1;32m     18\u001b[0m memory_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(memory_buffer)\n\u001b[1;32m     19\u001b[0m prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an assistant that retrieves relevant past queries from a memory buffer to provide context for answering the current input. **You MUST ONLY use the queries provided in the memory buffer. Do NOT hallucinate or use any other queries.**\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMemory Buffer (JSON):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmemory_json\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf no relevant queries are found, return an empty list.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m )\n\u001b[0;32m---> 38\u001b[0m structured_output: RelevantQueries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRelevantQueries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m structured_output\u001b[38;5;241m.\u001b[39mrelevant_queries\n",
      "Cell \u001b[0;32mIn[57], line 24\u001b[0m, in \u001b[0;36mBaseAgent.call_llm\u001b[0;34m(self, prompt, response_model)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call Gemini API and get structured output\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     {\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m\"\u001b[39m: [prompt]},\n\u001b[1;32m     22\u001b[0m ]\n\u001b[0;32m---> 24\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgemini\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Clean the response text\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     cleaned_response_text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ai/lib/python3.13/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ai/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ai/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ai/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ai/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ai/lib/python3.13/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ai/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ai/lib/python3.13/site-packages/grpc/_channel.py:1178\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1168\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1174\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1175\u001b[0m     (\n\u001b[1;32m   1176\u001b[0m         state,\n\u001b[1;32m   1177\u001b[0m         call,\n\u001b[0;32m-> 1178\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ai/lib/python3.13/site-packages/grpc/_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[1;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[1;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[0;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cell 8: Entry Point and Execution\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    DB_FILE = \"company_data.db\"  # Replace with your database file\n",
    "    USER_QUERY = \"How many people have booked at least 50 hours before 01/05/2024?\"  # Initial user query\n",
    "    pipeline = RAGPipeline(DB_FILE, USER_QUERY)\n",
    "    pipeline.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
